{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf86cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import float32,int32,int8,jit,cuda\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32,xoroshiro128p_uniform_float64\n",
    "from numba.cuda.random import xoroshiro128p_normal_float32\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from util import *\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2460b",
   "metadata": {},
   "source": [
    "# Using the decompression functions from data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64f9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def decompress2D(inn,states):\n",
    "    \"\"\"Inverse function of compress\n",
    "    Note: This is slightly changed to work with the correct tensor shape\"\"\"\n",
    "    sz,_,sx,sy=states.shape\n",
    "    #n is which 2d grid ur on, i is which set of 8 numbers you're on\n",
    "    n,i=cuda.grid(2)\n",
    "    #get the 2d grid\n",
    "    state=states[n][0]\n",
    "    num = inn[n][i]\n",
    "    for bit in range(8):\n",
    "        idx=i*8+bit\n",
    "        x = idx//sy\n",
    "        y = idx%sy\n",
    "        #make it a snake pattern. . .\n",
    "        if x%2==1:\n",
    "            y=sy-y-1\n",
    "        state[x][y]=1&(num>>bit)\n",
    "\n",
    "@cuda.jit\n",
    "def decompress1D(inn,states):\n",
    "    \"\"\"Similar to decompress 2D but instead of being an inverse to compress it squishes the 2D\n",
    "    array output into a 1D array (which is now in a snake pattern)\n",
    "    if states has shape [N,X,1] then out should have shape [M,Z/8]\n",
    "    and the blocks/threads should have shape [N,Z/8]\n",
    "    Here Z=X*Y where each state has shape [X,Y] on a 2D grid\n",
    "    \n",
    "    Note: This is slightly changed to work with the correct tensor shape\n",
    "    \"\"\"\n",
    "    #n is which grid ur on, i is which set of 8 numbers you're on\n",
    "    n,i=cuda.grid(2)\n",
    "    #get the grid\n",
    "    state=states[n]\n",
    "    num = inn[n][i]\n",
    "    for bit in range(8):\n",
    "        idx=i*8+bit\n",
    "        #get each value in 1d\n",
    "        state[idx][0]=1&(num>>bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1f7198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "ngpu=1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f9121a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsize=1024\n",
    "#N=32\n",
    "\n",
    "#bsize=2048\n",
    "#N=16\n",
    "\n",
    "bsize=4096\n",
    "N=8\n",
    "\n",
    "B=0.4407\n",
    "\n",
    "modeltype='CNN'\n",
    "\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcea955",
   "metadata": {},
   "source": [
    "# Implementing a simple RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70f9deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,device=device, **kwargs):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=1,hidden_size=128,batch_first=True)\n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(128,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        self.device=device\n",
    "        self.to(device)\n",
    "    def forward(self, input):\n",
    "        # h0 has shape [N,L,H]\n",
    "        h0=torch.zeros([1,input.shape[0],128]).to(device)\n",
    "        out,h=self.rnn(input,h0)\n",
    "        return self.lin(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f38df",
   "metadata": {},
   "source": [
    "# Using a 2D RNN\n",
    "\n",
    "https://github.com/FlorianPfisterer/2D-LSTM-Seq2Seq/blob/master/model/lstm2d_cell.py\n",
    "\n",
    "THIS IMPLEMENTATION LEAKS GPU MEMORY SOMEWHERE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889eac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM2dCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A 2d-LSTM Cell that computes it's hidden state and cell state based on\n",
    "        - an input x\n",
    "        - the previous horizontal hidden and cell state\n",
    "        - the previous vertical hidden and cell state\n",
    "    Args:\n",
    "        input_dim: the input dimension (i.e. second dimension of x)\n",
    "        state_dim: dimension of the hidden and cell state of this LSTM unit\n",
    "        device: the device (CPU / GPU) to run all computations on / store tensors on\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, state_dim,N, device):\n",
    "        super(LSTM2dCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.device = device\n",
    "\n",
    "        # input to state\n",
    "        self.W_x = nn.Linear(self.input_dim, self.state_dim * 5).to(self.device)\n",
    "        # previous horizontal hidden state to state\n",
    "        self.W_hor = nn.Linear(self.state_dim, self.state_dim * 5).to(self.device)\n",
    "        # previous vertical hidden state to state\n",
    "        self.W_ver = nn.Linear(self.state_dim, self.state_dim * 5).to(self.device)\n",
    "        \n",
    "        self.N=N\n",
    "        self.lin = nn.Sequential(\n",
    "                nn.Linear(state_dim,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,1),\n",
    "                nn.Sigmoid()\n",
    "            ).to(device)\n",
    "        self.setup()\n",
    "    def forward_pass(self, x, s_prev_hor, s_prev_ver, c_prev_hor, c_prev_ver):\n",
    "        \"\"\"\n",
    "        Forward pass of the 2d-LSTM Cell at horizontal step j and vertical step i (to compute c_ji and s_ji)\n",
    "        Args:\n",
    "            x: (batch x input_dim) input at horizontal step j\n",
    "            s_prev_hor: (batch x state_dim) hidden state of cell at previous horizontal step j-1, same vertical step i\n",
    "            s_prev_ver: (batch x state_dim) hidden state of cell at previous vertical step i-1, same horizontal step j\n",
    "            c_prev_hor: (batch x state_dim) cell state of cell at previous horizontal step j-1, same vertical step i\n",
    "            c_prev_ver: (batch x state_dim) cell state of cell at previous vertical step i-1, same horizontal step j\n",
    "        Returns:\n",
    "            c: (batch x state_dim) next cell state (c_ji)\n",
    "            s: (batch x state_dim) next hidden state (s_ji)\n",
    "        \"\"\"\n",
    "        pre_activation = self.W_x(x) + self.W_hor(s_prev_hor) + self.W_ver(s_prev_ver)\n",
    "        gates = pre_activation[:, :4*self.state_dim].sigmoid()\n",
    "\n",
    "        # retrieve input, forget, output and lambda gate from gates\n",
    "        i = gates[:, 0*self.state_dim:1*self.state_dim]\n",
    "        f = gates[:, 1*self.state_dim:2*self.state_dim]\n",
    "        o = gates[:, 2*self.state_dim:3*self.state_dim]\n",
    "        l = gates[:, 3*self.state_dim:4*self.state_dim]\n",
    "\n",
    "        c_candidate = pre_activation[:, 4*self.state_dim:].tanh()\n",
    "        c = f * (l * c_prev_hor + (1 - l) * c_prev_ver) + c_candidate * i\n",
    "        s = c.tanh() * o\n",
    "\n",
    "        return c, s\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"Sets up the structure that tells the rnn how to propogate the vertical and horizontal states.\n",
    "        Notably: X stores where to look for the previous rnn state in the vertical direction\n",
    "                 Y stores where to look for the previous rnn state in the horizontal direction\n",
    "                 Z stores where to save the current rnn output\n",
    "        \"\"\"\n",
    "        print(self.N**2-1)\n",
    "        N=self.N\n",
    "        self.X=np.zeros([N**2-1],dtype=np.int64)\n",
    "        self.Y=np.zeros([N**2-1],dtype=np.int64)\n",
    "        Z=np.arange(N**2).reshape(N,N)\n",
    "        Z[1::2,:]=Z[1::2,::-1]\n",
    "        #Z is in the snake pattern\n",
    "        Z=Z.reshape(N**2)[:N**2-1]\n",
    "        #pad states outside with the index of the starting state\n",
    "        states=np.pad(np.arange(N**2).reshape(N,N),[1,1],constant_values=N*(N-1))\n",
    "        for idx in range(N**2-1):\n",
    "            self.Y[idx]=states[Z[idx]//N+1,Z[idx]%N+2*((idx//N)%2)]\n",
    "            self.X[idx]=states[Z[idx]//N,Z[idx]%N+1]\n",
    "        self.Z=Z\n",
    "        \n",
    "    def forward(self,input):\n",
    "        N=self.N\n",
    "        X,Y,Z=self.X,self.Y,self.Z\n",
    "        #set up array to store hidden states\n",
    "        H,C= [True]*N**2,[True]*N**2\n",
    "        #set the starting state to zero\n",
    "        H[N*(N-1)]=C[N*(N-1)]=torch.zeros([input.shape[0],self.state_dim],device=device)\n",
    "        out = torch.zeros(input.shape,device=self.device)\n",
    "        read=[]\n",
    "        for idx in range(N**2-1):\n",
    "            #get horizontal input states\n",
    "            hx,cx=H[X[idx]],C[X[idx]]\n",
    "            #get vertical input states\n",
    "            hy,cy=H[Y[idx]],C[Y[idx]]\n",
    "            #get output states\n",
    "            cnext,hnext=self.forward_pass(input[:,idx,:],hx,hy,cx,cy)\n",
    "            #store output states for later use\n",
    "            C[Z[idx]],H[Z[idx]] = cnext,hnext\n",
    "            #apply linear layer\n",
    "            out[:,idx,:]=self.lin(hnext)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2fd47",
   "metadata": {},
   "source": [
    "# Visualizing 2D RNN Propogation\n",
    "\n",
    "Note 1: The bottom left (in state sources) stores the zero state\n",
    "\n",
    "Note 2: To get the position of the hidden state input in the propogation figures, just look for the cell in state sources with the matching color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f79f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"]= [12,4]\n",
    "tst = LSTM2dCell(1,128,4,device)\n",
    "X,Y = np.zeros(4**2)-1,np.zeros(4**2)-1\n",
    "X[tst.Z]=tst.X\n",
    "Y[tst.Z]=tst.Y\n",
    "X=X.reshape(4,4)\n",
    "Y=Y.reshape(4,4)\n",
    "Z=np.arange(16).reshape(4,4)\n",
    "\n",
    "fig,(a1,a2,a3)=plt.subplots(1,3)\n",
    "a1.imshow(Z,vmax=15,vmin=-1)\n",
    "a1.set_title(\"State Sources\")\n",
    "a2.imshow(X,vmax=15,vmin=-1)\n",
    "a2.set_title(\"Vertical Propogation\")\n",
    "a3.imshow(Y,vmax=15,vmin=-1)\n",
    "a3.set_title(\"Horizontal Propogation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07ffe8",
   "metadata": {},
   "source": [
    "# Blocked CNN :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a879c72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockedCNN(nn.Module):\n",
    "    def __init__(self,device,N):\n",
    "        super(BlockedCNN, self).__init__()\n",
    "        self.N=N\n",
    "        tmp=np.arange(N**2).reshape([N,N])\n",
    "        tmp[1::2,:]=tmp[1::2,::-1]\n",
    "        plt.imshow(tmp)\n",
    "        plt.show()\n",
    "        tmp2 = np.array([[tmp<=i for i in range(N**2-1)]])\n",
    "\n",
    "        self.mul=torch.tensor(tmp2).to(device).unsqueeze(2)\n",
    "        self.add=torch.tensor(tmp2-1).to(device).unsqueeze(2)\n",
    "        \n",
    "        print(self.add.shape)\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                nn.Conv2d(1,8,N//4,padding='same',padding_mode ='circular'),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(8,16,N//4,padding='same',padding_mode ='circular'),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Flatten(),\n",
    "                #Insize is 256, outsize is 10\n",
    "                nn.Linear(N**2,256),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(256,1),\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "        self.to(device)\n",
    "    def forward(self, input):\n",
    "        blocked=input.unsqueeze(1)*self.mul+self.add\n",
    "        a,b,c,d,e=blocked.shape\n",
    "        netin = blocked.reshape([a*b,c,d,e])\n",
    "        netout = self.net(netin)\n",
    "        ab,c2 = netout.shape\n",
    "        return netout.reshape([a,b,c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b6fb1",
   "metadata": {},
   "source": [
    "# Setting Parameters for what model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5341e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = np.load('data/traindata%d-%d.npy'%(N,B*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f96796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata = traindata[:traindata.shape[0]//5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a5f02eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51200000, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata = traindata[np.random.permutation(traindata.shape[0])]\n",
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8adb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata=traindata[:512000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645c195",
   "metadata": {},
   "source": [
    "# Making sure the shape of everything lines up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ecb948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1, 8, 8]) torch.Size([4096, 63, 1])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch=torch.zeros([bsize,N*N,1]).to(device)\n",
    "decompress1D[(bsize,N//2),(1,N//4)](traindata[0:bsize],batch)\n",
    "if modeltype=='CNN':\n",
    "    data=torch.zeros([bsize,1,N,N]).to(device)\n",
    "    decompress2D[(bsize,N//2),(1,N//4)](traindata[0:bsize],data)\n",
    "else:\n",
    "    data=batch[:,:-1,:]\n",
    "label=batch[:,1:,:]\n",
    "print(data.shape,label.shape)\n",
    "print(data[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888cb29",
   "metadata": {},
   "source": [
    "# Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cadf961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 63, 1, 8, 8])\n",
      "63\n",
      "torch.Size([4096, 63, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "typedict={'CNN':BlockedCNN(device,N),'2d':LSTM2dCell(1,128,N,device),'':RNN()}\n",
    "\n",
    "net = typedict[modeltype]\n",
    "with torch.no_grad():\n",
    "    print(net(data).shape)\n",
    "\n",
    "#training parameters\n",
    "lr = 1e-4 *(bsize/2048)\n",
    "beta1 = 0.9\n",
    "beta2=0.999\n",
    "#Using adam to optimize\n",
    "optimizer = torch.optim.Adam(\n",
    "    net.parameters(), \n",
    "    lr=lr, \n",
    "    betas=(beta1,beta2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7987994a",
   "metadata": {},
   "source": [
    "# Make sure to use a loss which will give you probabilities in your predictions.\n",
    "\n",
    "I know L2 loss and Binary Cross Entropy Loss will do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfceae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12499\n"
     ]
    }
   ],
   "source": [
    "Loss = nn.BCELoss()\n",
    "losses=[]\n",
    "validation=[]\n",
    "vidx= traindata.shape[0]//bsize-1\n",
    "print(vidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320fb799",
   "metadata": {},
   "source": [
    "# Network actually trains in a few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87371dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#set the last batch to validation\n",
    "#this is a super lazy validation set \n",
    "\n",
    "count=0\n",
    "for i in range(epoch):\n",
    "    #decided the last batch is validation \n",
    "    p = np.random.permutation(traindata.shape[0]//bsize)\n",
    "    t=time.time()\n",
    "    for idx in p:\n",
    "        #decompress the traindata with the gpu\n",
    "        decompress1D[(bsize,N//2),(1,N//4)](traindata[bsize*idx:bsize*(idx+1)],batch)\n",
    "        #starting N**2-1 are inputs\n",
    "        if modeltype=='CNN':\n",
    "            decompress2D[(bsize,N//2),(1,N//4)](traindata[bsize*idx:bsize*(idx+1)],data)\n",
    "        else:\n",
    "            data=batch[:,:-1,:]\n",
    "        #ending N**2-1 are predictions\n",
    "        real=batch[:,1:,:]\n",
    "        \n",
    "        pred = net(data)\n",
    "        loss = Loss(pred,real)\n",
    "        net.zero_grad()\n",
    "        if idx!=vidx:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.cpu().item())\n",
    "        else:\n",
    "            validation.append(loss.cpu().item())\n",
    "        count+=1\n",
    "        if (count%500)==0:\n",
    "            print(\"|\",end=\"\")\n",
    "            plt.plot(np.arange(len(losses))/vidx,losses,'.',color=(0,0,1,0.2))\n",
    "            plt.plot(np.arange(len(validation))+1,validation,'.',color=(1,0,0,0.5))\n",
    "            plt.yscale(\"log\")\n",
    "            plt.savefig(\"Loss.png\")\n",
    "            plt.close()\n",
    "            torch.save(net,\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))\n",
    "    if epoch//100==0 or i%(epoch//100)==0:\n",
    "        print(\"%.5f, %ds\"%(np.mean(losses[-p.size-1:]),time.time()-t),end=\"| \")\n",
    "        torch.save(net,\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.where(p==idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bb1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5d04a",
   "metadata": {},
   "source": [
    "# Plotting training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794f8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses))/vidx,losses,'.',color=(0,0,1,0.2))\n",
    "plt.plot(np.arange(len(validation))+1,validation,'.',color=(1,0,0,0.5))\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397f6b7",
   "metadata": {},
   "source": [
    "# Testing Our Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=np.load('data/testdata%d.npy'%N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c66ad",
   "metadata": {},
   "source": [
    "# Computing True and Predicted Energies\n",
    "\n",
    "Note: To go from probability to energy we look at the relation:\n",
    "\n",
    "$P(s)=\\frac{exp(-\\beta H(s))}{Z} = \\frac{1}{2} \\prod_{i=2}^{N^2}p(\\sigma_i|\\sigma_{i-1},\\sigma_{i-2} . . . \\sigma_1) $\n",
    "\n",
    "So\n",
    "\n",
    "$ln(P(s)) = -\\beta H(s) - ln(Z) = -ln(2)+ \\sum_{i=2}^{N^2}ln\\big[p(\\sigma_i|\\sigma_{i-1},\\sigma_{i-2} . . . \\sigma_1)\\big]$\n",
    "\n",
    "$-\\beta H(s) = -ln(2)+ \\sum_{i=2}^{N^2}ln\\big[p(\\sigma_i|\\sigma_{i-1},\\sigma_{i-2} . . . \\sigma_1)\\big]+ln(Z)$\n",
    "\n",
    "$H(s) = \\frac{ln(2)- \\sum_{i=2}^{N^2}ln\\big[p(\\sigma_i|\\sigma_{i-1},\\sigma_{i-2} . . . \\sigma_1)\\big]}{\\beta }-\\frac{ln(Z)}{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc7fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def IsingEnergy(grids,E):\n",
    "    \"\"\"Compute Energy of 2D ising lattice (J=1 h=0)\"\"\"\n",
    "    z,i,j=cuda.grid(3)\n",
    "    sz,sx,sy=grids.shape\n",
    "    s1=grids[z][i][j]*2-1\n",
    "    s2=grids[z][(i+1)%sx][j]*2-1\n",
    "    s3=grids[z][i][(j+1)%sy]*2-1\n",
    "    cuda.atomic.add(E,z,-s1*s2-s1*s3)\n",
    "\n",
    "def trueEnergies(grids,N):\n",
    "    \"\"\"Compute the true energies of a set of data-compressed ising lattices\"\"\"\n",
    "    testbatch=torch.zeros([grids.shape[0],1,N,N]).to(device)\n",
    "    decompress2D[(grids.shape[0],N//2),(1,N//4)](grids,testbatch)\n",
    "    testbatch=testbatch.squeeze(1)\n",
    "    E=np.zeros(grids.shape[0])\n",
    "    IsingEnergy[(grids.shape[0],N//8,N//8),(1,8,8)](testbatch,E)\n",
    "    return E\n",
    "\n",
    "def logprobability(grids,N):\n",
    "    \"\"\"compute the logscale probability of a set of data-compressed ising lattices\"\"\"\n",
    "    testbatch=torch.zeros([grids.shape[0],N*N,1]).to(device)\n",
    "    decompress1D[(grids.shape[0],N//2),(1,N//4)](grids,testbatch)\n",
    "    if modeltype=='CNN':\n",
    "        data=torch.zeros([grids.shape[0],1,N,N]).to(device)\n",
    "        decompress2D[(grids.shape[0],N//2),(1,N//4)](grids,data)\n",
    "    else:\n",
    "        data=testbatch[:,:-1,:]\n",
    "    real=testbatch[:,1:,:]\n",
    "    #real is going to be a set of actual values\n",
    "    #and pred is going to be a set of probabilities\n",
    "    #if real[i]=1 than you muptiply your conditional probability by pred[i]\n",
    "    #if real[i]=0 than you muliply by 1-pred[i]\n",
    "    with torch.no_grad():\n",
    "        pred = net(data)\n",
    "        ones = real*pred\n",
    "        zeros=(1-real)*(1-pred)\n",
    "        total = ones+zeros\n",
    "    #this is the sum you see in the cell above\n",
    "    logp=torch.sum(torch.log(total),dim=1).squeeze(1)-np.log(2)\n",
    "    return logp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa4fa0",
   "metadata": {},
   "source": [
    "# Looking at performance on Validation & Test Sets\n",
    "\n",
    "Note: The validation set has the same distribution of states as the training set\n",
    "Note: The test set has a very different distribution than our training set: States with energy zero and above will never actually have been seen by our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2def589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sets(ax0,ax1,c,diff=False,name=''):\n",
    "    \"\"\"Creates a plot of predicted vs true energy labels for the rnn\n",
    "       Since the rnn energy is relative, I set the average rnn ground state energy to the true ground state energy.\n",
    "       The rest of the energies can then be calculated relative to the ground state.\n",
    "    \"\"\"\n",
    "    # if the bytes are zero then all bits are zero\n",
    "    ground = np.zeros([2,N*N//8],dtype=np.uint8)\n",
    "    # if the value of the byte is 255 then all bits are 1\n",
    "    ground[1]=255\n",
    "    gprob = logprobability(ground,N)\n",
    "    gE = trueEnergies(ground,N)\n",
    "    off=-(gprob.cpu()/B).mean()-gE.mean()\n",
    "    \n",
    "    prob = logprobability(traindata[bsize*vidx:bsize*(vidx+1)],N)\n",
    "    trueE = trueEnergies(traindata[bsize*vidx:bsize*(vidx+1)],N)\n",
    "    relE=-prob.cpu()/B\n",
    "    #off=relE.mean()-trueE.mean()\n",
    "    print(off)\n",
    "    probB = logprobability(testdata[::max(N**2//8**2-1,1)].copy(),N)\n",
    "    trueEB = trueEnergies(testdata[::max(N**2//8**2-1,1)].copy(),N)\n",
    "    relEB=-probB.cpu()/B\n",
    "    if diff:\n",
    "        ax0.plot(trueE,relE-off-trueE,'.',color=c+[0.1],label=name)\n",
    "        ax0.plot(trueE,trueE*0,'k--')\n",
    "        ax1.plot(trueEB,relEB-off-trueEB,'.',color=c+[0.1],label=name)\n",
    "        ax1.plot(trueEB,trueEB*0,'k--')\n",
    "    else:\n",
    "        ax0.plot(trueE,relE-off,'.',color=c+[0.1],label=name)\n",
    "        ax0.plot(trueE,trueE,'k--')\n",
    "        ax1.plot(trueEB,relEB-off,'.',color=c+[0.1],label=name)\n",
    "        ax1.plot(trueEB,trueEB,'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"]= [12,4]\n",
    "fig,(ax0,ax1)=plt.subplots(1,2)\n",
    "plot_sets(ax0,ax1,[0,0,1])\n",
    "ax0.set_title(\"Pred vs True Train\")\n",
    "ax1.set_title(\"Pred vs True Test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6d076",
   "metadata": {},
   "source": [
    "# Comparing results at different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax0,ax1)=plt.subplots(1,2)\n",
    "\n",
    "colors = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "for i in range(epoch):\n",
    "    net = torch.load(\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))\n",
    "    net.setup()\n",
    "    torch.save(net,\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))\n",
    "    plot_sets(ax0,ax1,colors[i],name='Epoch %d'%(i+1))\n",
    "\n",
    "\n",
    "ax0.set_title(\"Pred vs True Train\")\n",
    "ax1.set_title(\"Pred vs True Test\")\n",
    "ax0.legend()\n",
    "ax1.legend()\n",
    "plt.show()\n",
    "\n",
    "fig,(ax0,ax1)=plt.subplots(1,2)\n",
    "\n",
    "for i in range(epoch):\n",
    "    net = torch.load(\"models/%s%d-%d-%d\"%(modeltype,N,B*10000,i))\n",
    "    #net.setup()\n",
    "    plot_sets(ax0,ax1,colors[i],True,name='Epoch %d'%(i+1))\n",
    "ax0.set_title(\"Pred-True Validation\")\n",
    "ax1.set_title(\"Pred-True Test\")\n",
    "ax0.legend()\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ab1692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
